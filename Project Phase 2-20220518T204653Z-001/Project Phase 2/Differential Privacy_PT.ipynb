{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Differential Privacy_PT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"m6hrD4gjan8M","executionInfo":{"status":"ok","timestamp":1638939556279,"user_tz":300,"elapsed":2609,"user":{"displayName":"Tanuja Thotakura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHxsC6HueqUuIrLZ3tUqd1Dwp0rDBabWy-zvyqlA=s64","userId":"05148336214682895046"}}},"source":[" import keras"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6yU8w8execwT","executionInfo":{"status":"ok","timestamp":1638939762964,"user_tz":300,"elapsed":205664,"user":{"displayName":"Tanuja Thotakura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHxsC6HueqUuIrLZ3tUqd1Dwp0rDBabWy-zvyqlA=s64","userId":"05148336214682895046"}},"outputId":"a7d05e28-75f7-4dd9-b13a-f3d1b4e47015"},"source":[" !pip install syft==0.2.9 tensorflow_privacy==0.7.3"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting syft==0.2.9\n","  Downloading syft-0.2.9-py3-none-any.whl (433 kB)\n","\u001b[?25l\r\u001b[K     |▊                               | 10 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 276 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 286 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 327 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 348 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 368 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 389 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 399 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 430 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 433 kB 4.7 MB/s \n","\u001b[?25hCollecting tensorflow_privacy==0.7.3\n","  Downloading tensorflow_privacy-0.7.3-py3-none-any.whl (251 kB)\n","\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 44.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 48.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 53.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 49.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 51 kB 48.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 61 kB 51.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 71 kB 51.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 81 kB 53.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 92 kB 52.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 102 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 112 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 122 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 133 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 143 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 153 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 163 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 174 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 184 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 194 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 204 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 215 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 225 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 235 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 245 kB 52.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 251 kB 52.9 MB/s \n","\u001b[?25hRequirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.1.4)\n","Requirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.0.3)\n","Collecting websockets~=8.1.0\n","  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 6.5 MB/s \n","\u001b[?25hCollecting tornado==4.5.3\n","  Downloading tornado-4.5.3.tar.gz (484 kB)\n","\u001b[K     |████████████████████████████████| 484 kB 35.4 MB/s \n","\u001b[?25hCollecting requests-toolbelt==0.9.1\n","  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n","\u001b[?25hCollecting psutil==5.7.0\n","  Downloading psutil-5.7.0.tar.gz (449 kB)\n","\u001b[K     |████████████████████████████████| 449 kB 37.9 MB/s \n","\u001b[?25hCollecting importlib-resources~=1.5.0\n","  Downloading importlib_resources-1.5.0-py2.py3-none-any.whl (21 kB)\n","Collecting syft-proto~=0.5.2\n","  Downloading syft_proto-0.5.3-py3-none-any.whl (66 kB)\n","\u001b[K     |████████████████████████████████| 66 kB 3.9 MB/s \n","\u001b[?25hRequirement already satisfied: dill~=0.3.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.3.4)\n","Collecting notebook==5.7.8\n","  Downloading notebook-5.7.8-py2.py3-none-any.whl (9.0 MB)\n","\u001b[K     |████████████████████████████████| 9.0 MB 16.2 MB/s \n","\u001b[?25hCollecting shaloop==0.2.1-alpha.11\n","  Downloading shaloop-0.2.1_alpha.11-py3-none-manylinux1_x86_64.whl (126 kB)\n","\u001b[K     |████████████████████████████████| 126 kB 48.2 MB/s \n","\u001b[?25hCollecting lz4~=3.0.2\n","  Downloading lz4-3.0.2-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 35.8 MB/s \n","\u001b[?25hCollecting torch~=1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 7.9 kB/s \n","\u001b[?25hCollecting aiortc==0.9.28\n","  Downloading aiortc-0.9.28-cp37-cp37m-manylinux2010_x86_64.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 33.4 MB/s \n","\u001b[?25hCollecting RestrictedPython~=5.0\n","  Downloading RestrictedPython-5.2-py2.py3-none-any.whl (28 kB)\n","Collecting flask-socketio~=4.2.1\n","  Downloading Flask_SocketIO-4.2.1-py2.py3-none-any.whl (16 kB)\n","Collecting phe~=1.4.0\n","  Downloading phe-1.4.0.tar.gz (35 kB)\n","Collecting requests~=2.22.0\n","  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 5.4 MB/s \n","\u001b[?25hCollecting numpy~=1.18.1\n","  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 52.8 MB/s \n","\u001b[?25hCollecting openmined.threepio==0.2.0\n","  Downloading openmined.threepio-0.2.0.tar.gz (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.1)\n","Collecting tblib~=1.6.0\n","  Downloading tblib-1.6.0-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: Pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (7.1.2)\n","Collecting websocket-client~=0.57.0\n","  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n","\u001b[K     |████████████████████████████████| 200 kB 45.8 MB/s \n","\u001b[?25hCollecting torchvision~=0.5.0\n","  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 48.6 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=21.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.7.3) (21.2.0)\n","Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.7.3) (2.7.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.7.3) (0.1.6)\n","Requirement already satisfied: tensorflow-probability>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.7.3) (0.15.0)\n","Collecting tensorflow-datasets>=4.4.0\n","  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 52.3 MB/s \n","\u001b[?25hRequirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow_privacy==0.7.3) (1.2.1)\n","Collecting aioice<0.7.0,>=0.6.17\n","  Downloading aioice-0.6.18-py3-none-any.whl (19 kB)\n","Collecting av<9.0.0,>=8.0.0\n","  Downloading av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2 MB)\n","\u001b[K     |████████████████████████████████| 37.2 MB 1.3 MB/s \n","\u001b[?25hCollecting crc32c\n","  Downloading crc32c-2.2.post0-cp37-cp37m-manylinux2010_x86_64.whl (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 201 kB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (1.15.0)\n","Collecting cryptography>=2.2\n","  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 22.5 MB/s \n","\u001b[?25hCollecting pylibsrtp>=0.5.6\n","  Downloading pylibsrtp-0.6.8-cp37-cp37m-manylinux2010_x86_64.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 3.3 MB/s \n","\u001b[?25hCollecting pyee>=6.0.0\n","  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.12.1)\n","Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.3.5)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.10.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.6.1)\n","Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.1.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.2.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (2.11.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (1.8.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.1.3)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.12.0)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.9.1)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (22.3.0)\n","Requirement already satisfied: pycparser>=2 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (2.21)\n","Collecting netifaces\n","  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dm-tree~=0.1.1->tensorflow_privacy==0.7.3) (1.15.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.0.1)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (7.1.2)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.1.0)\n","Collecting python-socketio>=4.3.0\n","  Downloading python_socketio-5.5.0-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.4 in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (4.8.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook==5.7.8->syft==0.2.9) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook==5.7.8->syft==0.2.9) (2.8.2)\n","Collecting python-engineio>=4.3.0\n","  Downloading python_engineio-4.3.0-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n","\u001b[?25hCollecting bidict>=0.21.0\n","  Downloading bidict-0.21.4-py3-none-any.whl (36 kB)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (1.24.3)\n","Collecting idna<2.9,>=2.5\n","  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (2021.10.8)\n","Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from syft-proto~=0.5.2->syft==0.2.9) (3.17.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow_privacy==0.7.3) (3.10.0.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow_privacy==0.7.3) (0.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow_privacy==0.7.3) (4.62.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow_privacy==0.7.3) (0.12.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow_privacy==0.7.3) (1.1.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow_privacy==0.7.3) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow_privacy==0.7.3) (1.4.0)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.13.0->tensorflow_privacy==0.7.3) (1.3.0)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.13.0->tensorflow_privacy==0.7.3) (0.4.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.13.0->tensorflow_privacy==0.7.3) (4.4.2)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook==5.7.8->syft==0.2.9) (0.7.0)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook==5.7.8->syft==0.2.9) (5.5.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (57.4.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.8.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.2.5)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (1.5.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (4.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.7.1)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook==5.7.8->syft==0.2.9) (2.6.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (3.0.6)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets>=4.4.0->tensorflow_privacy==0.7.3) (1.53.0)\n","Building wheels for collected packages: openmined.threepio, psutil, tornado, phe\n","  Building wheel for openmined.threepio (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openmined.threepio: filename=openmined.threepio-0.2.0-py3-none-any.whl size=80095 sha256=50b03d30f293a3e50368ca27aedce22b15b4546be272f44b1bca7bec16dcba27\n","  Stored in directory: /root/.cache/pip/wheels/97/3d/ce/4ca4386006e622cb87d5116e5e65026ec021d3cf906a9b3d5d\n","  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276466 sha256=8f042719e646cf47564c5dbbec55b9acf3f748b49925641320eeb8ede6ca4cab\n","  Stored in directory: /root/.cache/pip/wheels/b6/e7/50/aee9cc966163d74430f13f208171dee22f11efa4a4a826661c\n","  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-linux_x86_64.whl size=434054 sha256=b74ab6d1e4c3dd367e3a53b2c9f2a6880aa6ccfc4e662a2ff6b178de4fa75627\n","  Stored in directory: /root/.cache/pip/wheels/a2/45/43/36ec7a893e16c1212a6b1505ded0a2d73cf8e863a0227c8e04\n","  Building wheel for phe (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for phe: filename=phe-1.4.0-py2.py3-none-any.whl size=37362 sha256=41e125eb3fae0becb03c2373be25545c5fafc677aec20bd17e947689baaf0ffd\n","  Stored in directory: /root/.cache/pip/wheels/bb/ac/9b/b07a04fe6bb1418ab4ee06d6652757aef848b80363c4dac507\n","Successfully built openmined.threepio psutil tornado phe\n","Installing collected packages: tornado, python-engineio, netifaces, idna, bidict, torch, requests, python-socketio, pylibsrtp, pyee, numpy, importlib-resources, cryptography, crc32c, av, aioice, websockets, websocket-client, torchvision, tensorflow-datasets, tblib, syft-proto, shaloop, RestrictedPython, requests-toolbelt, psutil, phe, openmined.threepio, notebook, lz4, flask-socketio, aiortc, tensorflow-privacy, syft\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 5.1.1\n","    Uninstalling tornado-5.1.1:\n","      Successfully uninstalled tornado-5.1.1\n","  Attempting uninstall: idna\n","    Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.4.0\n","    Uninstalling importlib-resources-5.4.0:\n","      Successfully uninstalled importlib-resources-5.4.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: tensorflow-datasets\n","    Found existing installation: tensorflow-datasets 4.0.1\n","    Uninstalling tensorflow-datasets-4.0.1:\n","      Successfully uninstalled tensorflow-datasets-4.0.1\n","  Attempting uninstall: tblib\n","    Found existing installation: tblib 1.7.0\n","    Uninstalling tblib-1.7.0:\n","      Successfully uninstalled tblib-1.7.0\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Attempting uninstall: notebook\n","    Found existing installation: notebook 5.3.1\n","    Uninstalling notebook-5.3.1:\n","      Successfully uninstalled notebook-5.3.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","google-colab 1.0.0 requires notebook~=5.3.0; python_version >= \"3.0\", but you have notebook 5.7.8 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 4.5.3 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","bokeh 2.3.3 requires tornado>=5.1, but you have tornado 4.5.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed RestrictedPython-5.2 aioice-0.6.18 aiortc-0.9.28 av-8.0.3 bidict-0.21.4 crc32c-2.2.post0 cryptography-36.0.0 flask-socketio-4.2.1 idna-2.8 importlib-resources-1.5.0 lz4-3.0.2 netifaces-0.11.0 notebook-5.7.8 numpy-1.18.5 openmined.threepio-0.2.0 phe-1.4.0 psutil-5.7.0 pyee-8.2.2 pylibsrtp-0.6.8 python-engineio-4.3.0 python-socketio-5.5.0 requests-2.22.0 requests-toolbelt-0.9.1 shaloop-0.2.1a11 syft-0.2.9 syft-proto-0.5.3 tblib-1.6.0 tensorflow-datasets-4.4.0 tensorflow-privacy-0.7.3 torch-1.4.0 torchvision-0.5.0 tornado-4.5.3 websocket-client-0.57.0 websockets-8.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["idna","numpy","psutil","requests","tblib","tornado"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"8wRNzH5lhf_S"},"source":["Defines Loss Function"]},{"cell_type":"code","metadata":{"id":"wG1uOlyytrBW","executionInfo":{"status":"ok","timestamp":1638939780934,"user_tz":300,"elapsed":4783,"user":{"displayName":"Tanuja Thotakura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHxsC6HueqUuIrLZ3tUqd1Dwp0rDBabWy-zvyqlA=s64","userId":"05148336214682895046"}}},"source":["from absl import logging\n","import collections\n","import tensorflow as tf\n","\n","# from tensorflow_privacy.privacy.analysis import privacy_ledger\n","from tensorflow_privacy.privacy.dp_query import gaussian_query\n","\n","def make_optimizer_class(cls):\n","  \"\"\"Constructs a DP optimizer class from an existing one.\"\"\"\n","  parent_code = tf.compat.v1.train.Optimizer.compute_gradients.__code__\n","  child_code = cls.compute_gradients.__code__\n","  GATE_OP = tf.compat.v1.train.Optimizer.GATE_OP  # pylint: disable=invalid-name\n","  if child_code is not parent_code:\n","    logging.warning(\n","        'WARNING: Calling make_optimizer_class() on class %s that overrides '\n","        'method compute_gradients(). Check to ensure that '\n","        'make_optimizer_class() does not interfere with overridden version.',\n","        cls.__name__)\n","\n","  class DPOptimizerClass(cls):\n","    \"\"\"Differentially private subclass of given class cls.\"\"\"\n","\n","    _GlobalState = collections.namedtuple(\n","      '_GlobalState', ['l2_norm_clip', 'stddev'])\n","    \n","    def __init__(\n","        self,\n","        dp_sum_query,\n","        num_microbatches=None,\n","        unroll_microbatches=False,\n","        *args,  # pylint: disable=keyword-arg-before-vararg, g-doc-args\n","        **kwargs):\n","      \"\"\"Initialize the DPOptimizerClass.\n","\n","      Args:\n","        dp_sum_query: DPQuery object, specifying differential privacy\n","          mechanism to use.\n","        num_microbatches: How many microbatches into which the minibatch is\n","          split. If None, will default to the size of the minibatch, and\n","          per-example gradients will be computed.\n","        unroll_microbatches: If true, processes microbatches within a Python\n","          loop instead of a tf.while_loop. Can be used if using a tf.while_loop\n","          raises an exception.\n","      \"\"\"\n","      super(DPOptimizerClass, self).__init__(*args, **kwargs)\n","      self._dp_sum_query = dp_sum_query\n","      self._num_microbatches = num_microbatches\n","      self._global_state = self._dp_sum_query.initial_global_state()\n","      # TODO(b/122613513): Set unroll_microbatches=True to avoid this bug.\n","      # Beware: When num_microbatches is large (>100), enabling this parameter\n","      # may cause an OOM error.\n","      self._unroll_microbatches = unroll_microbatches\n","\n","    def compute_gradients(self,\n","                          loss,\n","                          var_list,\n","                          gate_gradients=GATE_OP,\n","                          aggregation_method=None,\n","                          colocate_gradients_with_ops=False,\n","                          grad_loss=None,\n","                          gradient_tape=None,\n","                          curr_noise_mult=0,\n","                          curr_norm_clip=1):\n","\n","      self._dp_sum_query = gaussian_query.GaussianSumQuery(curr_norm_clip, \n","                                                           curr_norm_clip*curr_noise_mult)\n","      self._global_state = self._dp_sum_query.make_global_state(curr_norm_clip, \n","                                                                curr_norm_clip*curr_noise_mult)\n","      \n","\n","      # TF is running in Eager mode, check we received a vanilla tape.\n","      if not gradient_tape:\n","        raise ValueError('When in Eager mode, a tape needs to be passed.')\n","\n","      vector_loss = loss()\n","      if self._num_microbatches is None:\n","        self._num_microbatches = tf.shape(input=vector_loss)[0]\n","      sample_state = self._dp_sum_query.initial_sample_state(var_list)\n","      microbatches_losses = tf.reshape(vector_loss, [self._num_microbatches, -1])\n","      sample_params = (self._dp_sum_query.derive_sample_params(self._global_state))\n","\n","      def process_microbatch(i, sample_state):\n","        \"\"\"Process one microbatch (record) with privacy helper.\"\"\"\n","        microbatch_loss = tf.reduce_mean(input_tensor=tf.gather(microbatches_losses, [i]))\n","        grads = gradient_tape.gradient(microbatch_loss, var_list)\n","        sample_state = self._dp_sum_query.accumulate_record(sample_params, sample_state, grads)\n","        return sample_state\n","    \n","      for idx in range(self._num_microbatches):\n","        sample_state = process_microbatch(idx, sample_state)\n","\n","      if curr_noise_mult > 0:\n","        grad_sums, self._global_state = (self._dp_sum_query.get_noised_result(sample_state, self._global_state))\n","      else:\n","        grad_sums = sample_state\n","\n","      def normalize(v):\n","        return v / tf.cast(self._num_microbatches, tf.float32)\n","\n","      final_grads = tf.nest.map_structure(normalize, grad_sums)\n","      grads_and_vars = final_grads#list(zip(final_grads, var_list))\n","    \n","      return grads_and_vars\n","\n","  return DPOptimizerClass\n","\n","\n","def make_gaussian_optimizer_class(cls):\n","  \"\"\"Constructs a DP optimizer with Gaussian averaging of updates.\"\"\"\n","\n","  class DPGaussianOptimizerClass(make_optimizer_class(cls)):\n","    \"\"\"DP subclass of given class cls using Gaussian averaging.\"\"\"\n","\n","    def __init__(\n","        self,\n","        l2_norm_clip,\n","        noise_multiplier,\n","        num_microbatches=None,\n","        ledger=None,\n","        unroll_microbatches=False,\n","        *args,  # pylint: disable=keyword-arg-before-vararg\n","        **kwargs):\n","      dp_sum_query = gaussian_query.GaussianSumQuery(\n","          l2_norm_clip, l2_norm_clip * noise_multiplier)\n","\n","      if ledger:\n","        dp_sum_query = privacy_ledger.QueryWithLedger(dp_sum_query,\n","                                                      ledger=ledger)\n","\n","      super(DPGaussianOptimizerClass, self).__init__(\n","          dp_sum_query,\n","          num_microbatches,\n","          unroll_microbatches,\n","          *args,\n","          **kwargs)\n","\n","    @property\n","    def ledger(self):\n","      return self._dp_sum_query.ledger\n","\n","  return DPGaussianOptimizerClass\n","GradientDescentOptimizer = tf.compat.v1.train.GradientDescentOptimizer\n","DPGradientDescentGaussianOptimizer_NEW = make_gaussian_optimizer_class(GradientDescentOptimizer)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjQ_bwBPas5l","executionInfo":{"status":"ok","timestamp":1638939840513,"user_tz":300,"elapsed":53576,"user":{"displayName":"Tanuja Thotakura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHxsC6HueqUuIrLZ3tUqd1Dwp0rDBabWy-zvyqlA=s64","userId":"05148336214682895046"}},"outputId":"793f7ef1-07c4-4a85-b319-5dd19b8a084c"},"source":["#import keras\n","#import tensorflow as tf\n","from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n","from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer\n","from keras.datasets import mnist,cifar100\n","import numpy as np\n","\n","# (mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n","(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = cifar100.load_data()\n","\n","mnist_x_train = mnist_x_train.astype( np.float32 ) / 255\n","mnist_x_test = mnist_x_test.astype( np.float32 ) / 255\n","\n","mnist_x_train = mnist_x_train.reshape( -1, 32, 32, 3)\n","mnist_x_test = mnist_x_test.reshape( -1, 32, 32, 3)\n","\n","mnist_y_train = tf.keras.utils.to_categorical(mnist_y_train)#keras.utils.to_categorical( mnist_y_train )\n","mnist_y_test = tf.keras.utils.to_categorical(mnist_y_test)#keras.utils.to_categorical( mnist_y_test )\n","\n","EPOCHS = 10\n","BATCH_SIZE = 500\n","\n","model = tf.keras.models.Sequential()\n","model.add( tf.keras.layers.Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=mnist_x_train.shape[ 1: ]  ) )\n","model.add( tf.keras.layers.MaxPooling2D( pool_size=(2, 2) ) )\n","model.add( tf.keras.layers.Conv2D( 64, kernel_size=(3, 3), activation='relu' ) )\n","model.add( tf.keras.layers.Flatten() )\n","model.add( tf.keras.layers.Dense( 128, activation='relu' ) )\n","model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n","optimizer = DPGradientDescentGaussianOptimizer_NEW(\n","   learning_rate = 0.0001,\n","   l2_norm_clip = 1.7,\n","   noise_multiplier = 1.0,\n","   num_microbatches = 150)\n","\n","loss = tf.keras.losses.CategoricalCrossentropy( from_logits=True, reduction=tf.losses.Reduction.NONE )\n","\n","model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","\n","model.fit(mnist_x_train, mnist_y_train,epochs= EPOCHS, steps_per_epoch=50000/500)\n","\n","print( 'test acc:', model.evaluate( mnist_x_test, mnist_y_test, batch_size=150 ) )\n","\n","eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=60000, batch_size=150, noise_multiplier=1.3, epochs=5, delta=4e-5)\n","print( 'epsilon: ', eps )\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169009152/169001437 [==============================] - 2s 0us/step\n","169017344/169001437 [==============================] - 2s 0us/step\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["100/100 [==============================] - 15s 28ms/step - loss: 4.5859 - accuracy: 0.0177\n","Epoch 2/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.4502 - accuracy: 0.0396\n","Epoch 3/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.1923 - accuracy: 0.0692\n","Epoch 4/10\n","100/100 [==============================] - 3s 27ms/step - loss: 3.9909 - accuracy: 0.0981\n","Epoch 5/10\n","100/100 [==============================] - 3s 27ms/step - loss: 3.8685 - accuracy: 0.1160\n","Epoch 6/10\n","100/100 [==============================] - 3s 27ms/step - loss: 3.7782 - accuracy: 0.1325\n","Epoch 7/10\n","100/100 [==============================] - 3s 27ms/step - loss: 3.6983 - accuracy: 0.1496\n","Epoch 8/10\n","100/100 [==============================] - 3s 27ms/step - loss: 3.6197 - accuracy: 0.1609\n","Epoch 9/10\n","100/100 [==============================] - 3s 27ms/step - loss: 3.5431 - accuracy: 0.1738\n","Epoch 10/10\n","100/100 [==============================] - 3s 27ms/step - loss: 3.4835 - accuracy: 0.1873\n","67/67 [==============================] - 1s 8ms/step - loss: 3.5477 - accuracy: 0.1749\n","test acc: [3.547664165496826, 0.17489999532699585]\n","DP-SGD with sampling rate = 0.25% and noise_multiplier = 1.3 iterated over 2000 steps satisfies differential privacy with eps = 0.446 and delta = 4e-05.\n","The optimal RDP order is 19.0.\n","epsilon:  (0.44569798462065274, 19.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CqrX0kCSas8P","executionInfo":{"status":"ok","timestamp":1638939910567,"user_tz":300,"elapsed":44594,"user":{"displayName":"Tanuja Thotakura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHxsC6HueqUuIrLZ3tUqd1Dwp0rDBabWy-zvyqlA=s64","userId":"05148336214682895046"}},"outputId":"d63e5c9d-e8a8-4eed-a18e-a2c693c94965"},"source":["import keras\n","import tensorflow as tf\n","from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n","from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer\n","from keras.datasets import mnist,cifar100\n","import numpy as np\n","\n","# (mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n","(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = cifar100.load_data()\n","\n","mnist_x_train = mnist_x_train.astype( np.float32 ) / 255\n","mnist_x_test = mnist_x_test.astype( np.float32 ) / 255\n","\n","mnist_x_train = mnist_x_train.reshape( -1, 32, 32, 3)\n","mnist_x_test = mnist_x_test.reshape( -1, 32, 32, 3)\n","\n","mnist_y_train = tf.keras.utils.to_categorical(mnist_y_train)#keras.utils.to_categorical( mnist_y_train )\n","mnist_y_test = tf.keras.utils.to_categorical(mnist_y_test)#keras.utils.to_categorical( mnist_y_test )\n","\n","EPOCHS = 10\n","BATCH_SIZE = 250\n","\n","model = tf.keras.models.Sequential()\n","model.add( tf.keras.layers.Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=mnist_x_train.shape[ 1: ]  ) )\n","model.add( tf.keras.layers.MaxPooling2D( pool_size=(2, 2) ) )\n","model.add( tf.keras.layers.Conv2D( 64, kernel_size=(3, 3), activation='relu' ) )\n","model.add( tf.keras.layers.Flatten() )\n","model.add( tf.keras.layers.Dense( 128, activation='relu' ) )\n","model.add( tf.keras.layers.Dense( 100, activation='softmax' ) )\n","optimizer=DPGradientDescentGaussianOptimizer_NEW(\n","   learning_rate = 0.1,\n","   l2_norm_clip = 1.2,\n","   noise_multiplier = 1.2,\n","   num_microbatches = 100)\n","\n","loss = tf.keras.losses.CategoricalCrossentropy( from_logits=True, reduction=tf.losses.Reduction.NONE )\n","\n","model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","\n","model.fit(mnist_x_train, mnist_y_train,epochs= EPOCHS, steps_per_epoch=50000/500)\n","\n","print( 'test acc:', model.evaluate( mnist_x_test, mnist_y_test, batch_size=250 ) )\n","\n","eps = compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=60000, batch_size=250, noise_multiplier=1.3, epochs=10, delta=4e-5)\n","print( 'epsilon: ', eps )\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["100/100 [==============================] - 3s 28ms/step - loss: 750972817113088.0000 - accuracy: 0.0098\n","Epoch 2/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.8901 - accuracy: 0.0096\n","Epoch 3/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.6396 - accuracy: 0.0094\n","Epoch 4/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.6390 - accuracy: 0.0102\n","Epoch 5/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.6399 - accuracy: 0.0102\n","Epoch 6/10\n","100/100 [==============================] - 3s 26ms/step - loss: 4.6389 - accuracy: 0.0098\n","Epoch 7/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.6388 - accuracy: 0.0095\n","Epoch 8/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.6401 - accuracy: 0.0094\n","Epoch 9/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.6403 - accuracy: 0.0096\n","Epoch 10/10\n","100/100 [==============================] - 3s 27ms/step - loss: 4.6390 - accuracy: 0.0101\n","40/40 [==============================] - 1s 9ms/step - loss: 4.6342 - accuracy: 0.0100\n","test acc: [4.634218215942383, 0.009999999776482582]\n","DP-SGD with sampling rate = 0.417% and noise_multiplier = 1.3 iterated over 2400 steps satisfies differential privacy with eps = 0.702 and delta = 4e-05.\n","The optimal RDP order is 17.0.\n","epsilon:  (0.7021092097853936, 17.0)\n"]}]}]}