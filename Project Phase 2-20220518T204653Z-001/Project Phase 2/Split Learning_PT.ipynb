{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Split Learning_PT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0Cmvogk4-rzs","executionInfo":{"status":"ok","timestamp":1638941297704,"user_tz":300,"elapsed":188329,"user":{"displayName":"Tanuja Thotakura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHxsC6HueqUuIrLZ3tUqd1Dwp0rDBabWy-zvyqlA=s64","userId":"05148336214682895046"}},"outputId":"04148032-94eb-45c3-e550-73518ccb1f48"},"source":["!pip install syft==0.2.5"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting syft==0.2.5\n","  Downloading syft-0.2.5-py3-none-any.whl (369 kB)\n","\u001b[K     |████████████████████████████████| 369 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.5) (1.1.4)\n","Collecting tornado==4.5.3\n","  Downloading tornado-4.5.3.tar.gz (484 kB)\n","\u001b[K     |████████████████████████████████| 484 kB 25.4 MB/s \n","\u001b[?25hCollecting phe~=1.4.0\n","  Downloading phe-1.4.0.tar.gz (35 kB)\n","Collecting torch~=1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.6 kB/s \n","\u001b[?25hCollecting requests~=2.22.0\n","  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 5.0 MB/s \n","\u001b[?25hCollecting websockets~=8.1.0\n","  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 6.8 MB/s \n","\u001b[?25hCollecting numpy~=1.18.1\n","  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.5) (1.0.3)\n","Collecting flask-socketio~=4.2.1\n","  Downloading Flask_SocketIO-4.2.1-py2.py3-none-any.whl (16 kB)\n","Collecting websocket-client~=0.57.0\n","  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n","\u001b[K     |████████████████████████████████| 200 kB 47.4 MB/s \n","\u001b[?25hRequirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.5) (1.4.1)\n","Collecting torchvision~=0.5.0\n","  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 51.9 MB/s \n","\u001b[?25hCollecting Pillow~=6.2.2\n","  Downloading Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 33.9 MB/s \n","\u001b[?25hCollecting lz4~=3.0.2\n","  Downloading lz4-3.0.2-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 41.5 MB/s \n","\u001b[?25hCollecting syft-proto~=0.4.1\n","  Downloading syft_proto-0.4.10-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n","\u001b[?25hCollecting tblib~=1.6.0\n","  Downloading tblib-1.6.0-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.5) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.5) (1.0.1)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.5) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.5) (2.11.3)\n","Collecting python-socketio>=4.3.0\n","  Downloading python_socketio-5.5.0-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask~=1.1.1->syft==0.2.5) (2.0.1)\n","Collecting python-engineio>=4.3.0\n","  Downloading python_engineio-4.3.0-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n","\u001b[?25hCollecting bidict>=0.21.0\n","  Downloading bidict-0.21.4-py3-none-any.whl (36 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.5) (1.24.3)\n","Collecting idna<2.9,>=2.5\n","  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.9 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.5) (2021.10.8)\n","Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from syft-proto~=0.4.1->syft==0.2.5) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->syft-proto~=0.4.1->syft==0.2.5) (1.15.0)\n","Building wheels for collected packages: tornado, phe\n","  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-linux_x86_64.whl size=434057 sha256=b1db7cb9eab6e738362b6f972da6f5a085aa27e278aeeee752ffa25ac8f68ddc\n","  Stored in directory: /root/.cache/pip/wheels/a2/45/43/36ec7a893e16c1212a6b1505ded0a2d73cf8e863a0227c8e04\n","  Building wheel for phe (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for phe: filename=phe-1.4.0-py2.py3-none-any.whl size=37362 sha256=a0556ab2e3686376b5ecef4a408b508e9a90bbc5fef528e78b7e005579b31bf6\n","  Stored in directory: /root/.cache/pip/wheels/bb/ac/9b/b07a04fe6bb1418ab4ee06d6652757aef848b80363c4dac507\n","Successfully built tornado phe\n","Installing collected packages: python-engineio, bidict, torch, python-socketio, Pillow, numpy, idna, websockets, websocket-client, tornado, torchvision, tblib, syft-proto, requests, phe, lz4, flask-socketio, syft\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: idna\n","    Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 5.1.1\n","    Uninstalling tornado-5.1.1:\n","      Successfully uninstalled tornado-5.1.1\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: tblib\n","    Found existing installation: tblib 1.7.0\n","    Uninstalling tblib-1.7.0:\n","      Successfully uninstalled tblib-1.7.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 4.5.3 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 6.2.2 which is incompatible.\n","bokeh 2.3.3 requires tornado>=5.1, but you have tornado 4.5.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed Pillow-6.2.2 bidict-0.21.4 flask-socketio-4.2.1 idna-2.8 lz4-3.0.2 numpy-1.18.5 phe-1.4.0 python-engineio-4.3.0 python-socketio-5.5.0 requests-2.22.0 syft-0.2.5 syft-proto-0.4.10 tblib-1.6.0 torch-1.4.0 torchvision-0.5.0 tornado-4.5.3 websocket-client-0.57.0 websockets-8.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","numpy","tornado"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD7YL87A-sGK","executionInfo":{"status":"ok","timestamp":1638941310602,"user_tz":300,"elapsed":6239,"user":{"displayName":"Tanuja Thotakura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHxsC6HueqUuIrLZ3tUqd1Dwp0rDBabWy-zvyqlA=s64","userId":"05148336214682895046"}},"outputId":"5caf46e2-ef0d-430a-d317-66b41fd134a3"},"source":["import torch\n","import syft as sy\n","\n","# allow pysyft to work its magic on torch tensors\n","hook = sy.TorchHook(torch)\n","\n","# create a virtual worker. in an actual setting this would be on a different machine\n","client = sy.VirtualWorker( hook, id='client' )\n","\n","# define a tensor and send it to the client\n","x = torch.tensor([1,2,3,4,5])\n","# this leaves us with a pointer to the tensor\n","x_pointer = x.send( client )\n","\n","# check out some meta data\n","print( x_pointer )\n","print( client._objects )\n","\n","# we can use this pointers like normal tensors\n","result = x_pointer + x_pointer\n","print( result )\n","\n","# if we want the result we can call get() to send the tensor back to us\n","result_local = result.get()\n","# once we call get() it removes the tensor from the other side and our pointer\n","# becomes invalid\n","print( result_local )\n","print( client._objects )\n","# print( result )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(Wrapper)>[PointerTensor | me:66264475649 -> client:2558623762]\n","{67560727805: <Plan Plan id:67560727805 owner:client Tags: #fss_eq_plan_1 built>\n",", 99197118697: <Plan Plan id:99197118697 owner:client Tags: #fss_eq_plan_2 built>\n",", 31906307257: <Plan Plan id:31906307257 owner:client Tags: #fss_comp_plan_1 built>\n",", 69402026607: <Plan Plan id:69402026607 owner:client Tags: #fss_comp_plan_2 built>\n",", 71980366719: <Plan Plan id:71980366719 owner:client Tags: #xor_add_1 built>\n",", 34977975923: <Plan Plan id:34977975923 owner:client Tags: #xor_add_2 built>\n",", 2558623762: tensor([1, 2, 3, 4, 5])}\n","(Wrapper)>[PointerTensor | me:65133425596 -> client:83943614914]\n","tensor([ 2,  4,  6,  8, 10])\n","{67560727805: <Plan Plan id:67560727805 owner:client Tags: #fss_eq_plan_1 built>\n",", 99197118697: <Plan Plan id:99197118697 owner:client Tags: #fss_eq_plan_2 built>\n",", 31906307257: <Plan Plan id:31906307257 owner:client Tags: #fss_comp_plan_1 built>\n",", 69402026607: <Plan Plan id:69402026607 owner:client Tags: #fss_comp_plan_2 built>\n",", 71980366719: <Plan Plan id:71980366719 owner:client Tags: #xor_add_1 built>\n",", 34977975923: <Plan Plan id:34977975923 owner:client Tags: #xor_add_2 built>\n",", 2558623762: tensor([1, 2, 3, 4, 5])}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_usVkRQ-sIo","executionInfo":{"status":"ok","timestamp":1638942359949,"user_tz":300,"elapsed":571105,"user":{"displayName":"Tanuja Thotakura","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHxsC6HueqUuIrLZ3tUqd1Dwp0rDBabWy-zvyqlA=s64","userId":"05148336214682895046"}},"outputId":"5bb074c4-88c7-4058-fcaf-973d15074fda"},"source":["import torch\n","from torchvision import datasets, transforms  # it may raise errors, and you need restart the runtime\n","from torch import nn, optim\n","import syft as sy\n","hook = sy.TorchHook(torch)\n","\n","epochs = 15\n","\n","# Data preprocessing\n","transform = transforms.Compose([transforms.ToTensor(),\n","                              transforms.Normalize((0.5,), (0.5,)),\n","                              ])\n","trainset = datasets.CIFAR100('cifar100', download=True, train=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","torch.manual_seed(0)\n","\n","# Define our model segments\n","\n","input_size = 3072\n","hidden_sizes = [128, 640]\n","output_size = 100\n","\n","models = [\n","    nn.Sequential(\n","                nn.Linear(input_size, hidden_sizes[0]),\n","                nn.ReLU(),\n","                nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n","                nn.ReLU(),\n","    ),\n","    nn.Sequential(\n","                nn.Linear(hidden_sizes[1], output_size),\n","                nn.LogSoftmax(dim=1)\n","    )\n","]\n","\n","# Create optimisers for each segment and link to their segment\n","optimizers = [\n","    optim.SGD(model.parameters(), lr=0.01,)\n","    for model in models\n","]\n","\n","# create some workers\n","alice = sy.VirtualWorker(hook, id=\"alice\")\n","bob = sy.VirtualWorker(hook, id=\"bob\")\n","workers = alice, bob\n","\n","# Send Model Segments to starting locations\n","model_locations = [alice, bob]\n","\n","for model, location in zip(models, model_locations):\n","    model.send(location)\n","\n","def train(x, target, models, optimizers):\n","    # Training Logic\n","\n","    #1) erase previous gradients (if they exist)\n","    for opt in optimizers:\n","        opt.zero_grad()\n","\n","    #2) make a prediction\n","    a = models[0](x)\n","\n","    #3) break the computation graph link, and send the activation signal to the next model\n","    remote_a = a.move(models[1].location, requires_grad=True)\n","\n","    #4) make prediction on next model using received signal\n","    pred = models[1](remote_a)\n","\n","    #5) calculate how much we missed\n","    criterion = nn.NLLLoss()\n","    loss = criterion(pred, target)\n","\n","    #6) figure out which weights caused us to miss\n","    loss.backward()\n","\n","    # 7) send gradient of the received activation signal to the model behind\n","    # grad_a = remote_a.grad.copy().move(models[0].location)\n","\n","    # 8) backpropagate on bottom model given this gradient\n","    # a.backward(grad_a)\n","\n","    #9) change the weights\n","    for opt in optimizers:\n","        opt.step()\n","\n","    #10) print our progress\n","    return loss.detach().get()\n","\n","for i in range(epochs):\n","    running_loss = 0\n","    for images, labels in trainloader:\n","        images = images.send(alice)\n","        images = images.view(images.shape[0], -1)\n","        labels = labels.send(bob)\n","        \n","        loss = train(images, labels, models, optimizers)\n","        running_loss += loss\n","\n","    else:\n","        print(\"Epoch {} - Training loss: {}\".format(i, running_loss/len(trainloader)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Torch was already hooked... skipping hooking process\n"]},{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Epoch 0 - Training loss: 4.478142738342285\n","Epoch 1 - Training loss: 4.085339546203613\n","Epoch 2 - Training loss: 3.8604989051818848\n","Epoch 3 - Training loss: 3.7098429203033447\n","Epoch 4 - Training loss: 3.609361171722412\n","Epoch 5 - Training loss: 3.5366435050964355\n","Epoch 6 - Training loss: 3.4761979579925537\n","Epoch 7 - Training loss: 3.4220638275146484\n","Epoch 8 - Training loss: 3.374359369277954\n","Epoch 9 - Training loss: 3.329080581665039\n","Epoch 10 - Training loss: 3.2829349040985107\n","Epoch 11 - Training loss: 3.240553379058838\n","Epoch 12 - Training loss: 3.2006115913391113\n","Epoch 13 - Training loss: 3.1606180667877197\n","Epoch 14 - Training loss: 3.123532295227051\n"]}]}]}