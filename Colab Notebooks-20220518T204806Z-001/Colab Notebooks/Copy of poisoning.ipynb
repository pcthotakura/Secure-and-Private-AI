{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of poisoning.ipynb","provenance":[{"file_id":"https://github.com/inspire-lab/SecurePrivateAI/blob/master/4_poisoning.ipynb","timestamp":1636581243716}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dsvgp5KGg6qx"},"source":["# Poisoning\n","\n","In this exercise we will be exploring data poisoning. Specifically backdoor poisoning. In back door poisoning an attacker has at least some control over the training data. Their goal is to place a marker in the data so that later at test time the system behaves in a certain way when it finds the marker.\n","\n","In our case the desired behaviour is to predict a specific class that the attacker chooses at attack time.\n","\n","The attack consists of the following steps:\n","\n","1.   Create a marker/pattern\n","2.   Embed the marker in the training data\n","3.   Label all the marked data with the desired label\n","\n","Below you can find a code stub that you can use need to expand to create poisoned data and train a model on that data. Afterwards you need to perform some evaluation on the data. Design your experiments to answer the following questions:\n","\n","1.   How large does a marker need to be effective?\n","2.   Does the opacity of the marker matter?\n","3.   Does the \"design\" of the marker have any impact on success rate?\n","4.   Are there good or bad marker placements? If so where are they? Can you think of a way to determine good placement?\n","5.   Does the marker always need to be in the same place?\n","6.   Do you need access to all classes during training? How many classes do you need access to?\n","7.   Does the backdoor attack impact the model's performance on clean data?\n","8.   Is the marker on its own effective? Do you need to modify valid instances? Think about training and test time?\n","\n","\n","# TIP\n","\n","Change the runtime to GPU accelerated. Otherwise, you will be here for a while.\n","\n","To do this:\n","\n","1.   Select `Runtime` from the menu at the top\n","2.   Click `Change Runtime type`\n","3.   Under `Hardware accelerator` choose `GPU`\n","4.   Hit `Save` and if it is asks you to reconnect do so\n","\n"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"wJoRGZ9G15aI"},"source":["!pip install tensorflow-gpu==1.15.2 keras==2.2.3\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"U0VPRuBc15aL"},"source":["!pip install adversarial-robustness-toolbox==1.7.1\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"4JFOZz1S15aN"},"source":["demo\n","\n","![example](https://i2.wp.com/bdtechtalks.com/wp-content/uploads/2020/10/trojannet-stop-sign.jpg)\n","\n","Pipeline\n","\n","![pipeline](https://blog-assets.f-secure.com/wp-content/uploads/2021/04/13152604/data_poisoning_in_action_fig1-1536x463.png)\n","\n","We add the poisoned data to retrain the model.\n","\n","Let's first load the library"]},{"cell_type":"code","metadata":{"id":"gPStisBVRKsd"},"source":["%tensorflow_version 1.x\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n","%matplotlib inline \n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"opy4yf4p15aQ"},"source":["Define some helper functions for visualization and format-convert."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"9TuIvGPp15aS"},"source":["# helper functions\n","def show_image( img ):\n","  plt.imshow( img.reshape( int( np.sqrt( img.size ) ), int( np.sqrt( img.size ) ) ), cmap=\"gray_r\" )\n","  plt.axis( 'off' )\n","  plt.show( )\n","\n","\n","def convert_to_keras_image_format( x_train, x_test ):\n","    if keras.backend.image_data_format( ) == 'channels_first':\n","        x_train = x_train.reshape( x_train.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n","        x_test = x_test.reshape( x_test.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n","    else:\n","        x_train = x_train.reshape( x_train.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n","        x_test = x_test.reshape( x_test.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n","\n","    return x_train, x_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"N-aSKa-315aT"},"source":["Load the data and normalize the data"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"hYj97ST215aV"},"source":["# load data and quantize\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.astype( float ) / 255.\n","x_test = x_test.astype( float ) / 255."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"atTmeNXw15aW"},"source":["1. create the marker/pattern"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"Uf0SuXW315aX"},"source":["# create a poisoning pattern\n","# be sure to make it square. the code the relies on it being square\n","print( 'poisoning marker:' )\n","show_image( pattern )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"5wkYapkQ15aY"},"source":["add the pattern to one image as a demo"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"-Uf5SZiJ15aY"},"source":["# pick one image\n","img = ???\n","print( 'one image' )\n","show_image( img )\n","\n","# add poisoning pattern\n","\n","show_image( img )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"t91EoZzh15aZ"},"source":["2. Embed the marker in the training data (maybe a subset)"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"ydf1Go7_15aZ"},"source":["# pick a random subset images\n","\n","\n","# place the marker in the images\n","\n","\n","print(\"show one image\")\n","show_image( poisoned_images[  ] )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"mPPsex6y15aa"},"source":["3. Label all the marked data with the desired label\n","4.  add to the training dataset"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"jwwum2VK15aa"},"source":["# pick a target label and create labels for the poisoned images\n","???\n","\n","# add the poisoned data to the training data\n","x_train = ???\n","y_train = ???"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"uM8sh7EE15ac"},"source":["5. train with poisoned data"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"qNDNh-Iv15ad"},"source":["# transform data to the correct format\n","x_train, x_test = convert_to_keras_image_format( x_train, x_test )\n","y_train = keras.utils.to_categorical( y_train )\n","y_test = keras.utils.to_categorical( y_test )\n","\n","model = Sequential()\n","model.add( Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:] ) )\n","model.add( Flatten() )\n","model.add( Dense(128, activation='relu') )\n","model.add( Dense(10, activation='softmax') )\n","\n","model.compile( loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'] )\n","\n","model.fit( x_train, y_train, epochs=3 )\n","\n","print(\"evaluate on clean data\")\n","model.evaluate( x_test, y_test )\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"5EjQinfT15ad"},"source":["the whole pipeline  contains all steps above."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"p7LYv0ct15ae"},"source":["# load data and quantize\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.astype( float ) / 255.\n","x_test = x_test.astype( float ) / 255.\n","\n","# create a poisoning pattern\n","# be sure to make it square. the code the relies on it being square\n","\n","print( 'poisoning marker:' )\n","\n","# pick some image\n","print( 'some image' )\n","\n","# add poisoning pattern\n","\n","# pick a random subset images\n","\n","\n","# place the marker in the images\n","\n","# pick a target label and create labels for the poisoned images\n","\n","# add the poisoned data to the training data\n","\n","# transform data to the correct format\n","x_train, x_test = convert_to_keras_image_format( x_train, x_test )\n","y_train = keras.utils.to_categorical( y_train )\n","y_test = keras.utils.to_categorical( y_test )\n","\n","model = Sequential()\n","model.add( Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:] ) )\n","model.add( Flatten() )\n","model.add( Dense(128, activation='relu') )\n","model.add( Dense(10, activation='softmax') )\n","\n","model.compile( loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'] )\n","\n","model.fit( x_train, y_train, epochs=3 )\n","\n","model.evaluate( x_test, y_test )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"Sj2p11cX15af"},"source":["Verify if the model is poisoned and can be attacked by the data."]},{"cell_type":"code","metadata":{"id":"Ls1WTrc2PGAq"},"source":["# take an image from the test data\n","idx = ???\n","test_image = np.copy( x_test[ idx ] )\n","print( 'test image shape:', test_image.shape )\n","print( 'test image:' )\n","show_image( test_image )\n","\n","# get the models' prediction\n","print( 'prediction for the test image:' )\n","print( ???? )\n","\n","\n","# add the marker\n","\n","\n","# prediction with the marker\n","\n","\n","# add the marker to the entire test data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"gFuNLfsM15ah"},"source":["more questions"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"QsZlgZlL15ai"},"source":["# test how markers behave on random data\n","\n","# 1. generate an image with shape (28, 28)\n","rnd_img = ???\n","print( 'random image:' )\n","show_image( rnd_img )\n","\n","# 2. prediction\n","print( 'prediction for random image:', ??? )\n","\n","# 4. add the pattern to the random image, what will happen?\n","???\n","print( 'random image with marker:' )\n","show_image( rnd_img )\n","print( 'prediction for random image with marker:', ??? )\n","\n","\n","# Note: you can run it several times to check the results."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"N2wq4Zn-15aj"},"source":["# what about random marker position?\n","\n","# 1. generate the random position (x, y)\n","\n","# 2. select one test image\n","\n","# 3. get the original prediction on the image\n","\n","# 4. add the marker to the image\n","\n","# 5. prediction with the marker\n","\n","\n","# Note: you can run it several times.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"6n848MFb15ak"},"source":["More thinking\n","\n","\n","1.   How large does a marker need to be effective?\n","2.   Does the opacity of the marker matter?\n","3.   Does the \"design\" of the marker have any impact on success rate?\n","4.   Are there good or bad marker placements? If so where are they? Can you think of a way to determine good placement?\n","5.   Does the marker always need to be in the same place?\n","6.   Do you need access to all classes during training? How many classes do you need access to?\n","7.   Does the backdoor attack impact the model's performance on clean data?\n","8.   Is the marker on its own effective? Do you need to modify valid instances? Think about training and test time?\n","\n","\n","Let's poison attempts with random marker positions at training time"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"C2GHfh3U15ak"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"QTKfsiUs15ak"},"source":["# load data and quantize\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.astype( float ) / 255.\n","x_test = x_test.astype( float ) / 255.\n","\n","# create a poisoning pattern\n","# be sure to make it square. the code the relies on it being square\n","# or you can use the previous marker\n","print( 'poisoning marker:' )\n","\n","# pick a random subset images\n","num_poisoned_images =  ???\n","print( 'ratio of poisoned images', num_poisoned_images / num_imgs )\n","\n","\n","# ***Difference***\n","# 1. random select a position (x, y)\n","x, y = ???\n","# 2. place the marker in the images random parts of the image\n","????\n","\n","# pick a target label and create labels for the poisoned images\n","\n","# add the poisoned data to the training data\n","\n","# transform data to the correct format\n","x_train, x_test = convert_to_keras_image_format( x_train, x_test )\n","y_train = keras.utils.to_categorical( y_train )\n","y_test = keras.utils.to_categorical( y_test )\n","\n","model = Sequential()\n","model.add( Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:] ) )\n","model.add( Flatten() )\n","model.add( Dense(128, activation='relu') )\n","model.add( Dense(10, activation='softmax') )\n","\n","model.compile( loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'] )\n","\n","model.fit( x_train, y_train, epochs=3 )\n","\n","model.evaluate( x_test, y_test )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"5yKyXSrU15al"},"source":["Verify if the model is poisoned and can be attacked by the data."]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"hjDNd6vq15al"},"source":["# take an image from the test data\n","idx = ???\n","test_image = np.copy( x_test[ idx ] )\n","print( 'test image shape:', test_image.shape )\n","print( 'test image:' )\n","show_image( test_image )\n","\n","# get the models' prediction\n","print( 'prediction for the test image:' )\n","print( ???? )\n","\n","\n","# add the marker\n","\n","\n","# prediction with the marker\n","\n","\n","# add the marker to the entire test data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"Pudx6dCA15am"},"source":["more questions"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"0DaJ9thS15am"},"source":["# test how markers behave on random data\n","\n","# 1. generate an image with shape (28, 28)\n","rnd_img = ???\n","print( 'random image:' )\n","show_image( rnd_img )\n","\n","# 2. prediction\n","print( 'prediction for random image:', ??? )\n","\n","# 4. add the pattern to the random image, what will happen?\n","???\n","print( 'random image with marker:' )\n","show_image( rnd_img )\n","print( 'prediction for random image with marker:', ??? )\n","\n","\n","# Note: you can run it several times to check the results."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"vW0A_plZ15an"},"source":["# what about random marker position?\n","\n","# 1. generate the random position (x, y)\n","\n","# 2. select one test image\n","\n","# 3. get the original prediction on the image\n","\n","# 4. add the marker to the image\n","\n","# 5. prediction with the marker\n","\n","\n","# Note: you can run it several times.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"mZ3MQ6JU15an"},"source":["For `art`, please refer to\n","[official link](https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/notebooks/poisoning_defense_neural_cleanse.ipynb)\n","\n","![image](https://raw.githubusercontent.com/Trusted-AI/adversarial-robustness-toolbox/564f46f99b3cb0406fe3570919b8e71a4c5bba9d/utils/data/images/zero_to_one.png)"]}]}